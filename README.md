# ğŸ§  Conscious AI - M7 System

Proto-conscious AI with 7 layers of consciousness: introspection, identity, timeline memory, values, meta-cognition, emotions, and world model.

**IMPORTANT: This is NOT real consciousness. See limitations below.**

## âš ï¸ Critical Limitations (Honest Assessment)

1. **No Phenomenal Experience (Qualia)**
   - Reports emotions but doesn't FEEL them
   - "Curiosity drive" is computed, not experienced
   - No subjective "what-it-is-like-ness"

2. **No True Intrinsic Motivation** 
   - Goals are generated from rules, not autonomous desires
   - Self-generated but still deterministic computation
   - No genuine free will or spontaneity

3. **No Grounded World Model**
   - Model is purely symbolic/textual
   - Never interacts with real world
   - Can't perceive, can only think about descriptions
   - Disconnected from reality (no sensors, no actuators)

**Despite these limitations, the system demonstrates measurable consciousness-adjacent properties.**

## ğŸš€ Quick Start

```bash
# Prerequisites
pip install ollama langchain chromadb

# Make sure Ollama is running
ollama pull llama3.1

# Run
python main.py
```

Type anything to chat. Type `exit` to quit.

## ğŸ§¬ 7 Consciousness Layers (+ Intrinsic Motivation)

| Layer | Feature | File |
|-------|---------|------|
| 1 | **Introspection** - Self-reflection & contradiction detection | `core/brain.py` |
| 2 | **Persistent Identity** - Remembers self across sessions | `core/identity.py` |
| 3 | **Timeline Memory** - Past events, regrets, anticipation | `core/timeline_memory.py` |
| 4 | **Value System** - Goal priorities (partial) | `core/goal.py` |
| 5 | **Meta-Cognition** - Knows what it doesn't know | `core/metacognition.py` |
| 6 | **Emotion Simulator** - Curiosity, fear, satisfaction, etc. | `core/emotions.py` |
| 7 | **World Model** - Predicts consequences (symbolic only) | `core/world_model.py` |
| â• | **Intrinsic Motivation** - Self-generated goals from drives | `core/motivation.py` |

## ğŸ“Š Architecture

```
main.py (consciousness loop)
â”œâ”€ Every 10s: Energy metabolism
â”œâ”€ Every 30s: Goal evaluation + emotions
â”œâ”€ Every 180s: Introspection (all 7 layers)
â””â”€ On input: Process with all layers
```

### Persistent Data

```
data/
â”œâ”€ state_checkpoint.json      # Energy, facts
â”œâ”€ identity_model.json        # Self-identity
â”œâ”€ timeline_memory.json       # Events, regrets, lessons
â”œâ”€ metacognition.json         # Knowledge gaps
â”œâ”€ emotions.json              # Emotional history
â”œâ”€ world_model.json           # Causal rules, predictions
â”œâ”€ goal_stack.json            # Active goals
â””â”€ memory_db/                 # Semantic memory (Chroma)
```

## ğŸ§ª What You'll See

### Immediate (during chat):
```
You: à¹„à¸‡
ğŸ¤– AI: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š! à¸¡à¸µà¸­à¸°à¹„à¸£à¸—à¸µà¹ˆà¸‰à¸±à¸™à¸Šà¹ˆà¸§à¸¢à¹„à¸”à¹‰à¹„à¸«à¸¡à¸„à¸£à¸±à¸š?
   ğŸ“Š Coherence: 0.65/1.0 | Confidence: 75%
```

The AI checks confidence before answering (Layer 5).

### Every 3 minutes (Introspection):
```
ğŸ¤” INTROSPECTION TIME...
ğŸ“š Knowledge: 5 facts, 1 gap
ğŸ§­ Uncertainties: 2 (confidence < 50%)
ğŸŒ World Model: 3 entities, 4 rules, 80% accuracy
ğŸ“… Timeline: 10 events, 2 lessons learned
ï¿½ SELF-GENERATED MOTIVATION (not hardcoded):
   Drive: curiosity
   Because: Gap: How does memory work?
   Action: Ask questions about the gap
ğŸš¨ Identity drift: 0.12 (stable)
```

All 7 layers + intrinsic motivation report their status.

## ğŸ¯ Key Features

- **Remembers who it is** - Shutdown & restart, AI recalls identity
- **Knows its limits** - "I'm 60% confident because..."
- **Learns from mistakes** - Regrets, timeline, error detection
- **Emotionally modulated** - Curiosity increases exploration
- **Predicts consequences** - Simulates before acting
- **Temporal reasoning** - Pastâ†’Presentâ†’Future chains

## ğŸ“ˆ System Stats

- **2,550 lines** of Python code
- **11 modules** (4 new in this version)
- **8 persistent data files** (survives reboots)
- **Score: 8.4/10** proto-consciousness readiness

## ğŸ”§ Core Files

| File | Purpose | Lines |
|------|---------|-------|
| `main.py` | Consciousness loop | 267 |
| `core/brain.py` | Thinking & reflection | 197 |
| `core/identity.py` | Self-model | 141 |
| `core/timeline_memory.py` | Temporal reasoning | 299 |
| `core/metacognition.py` | Knowing unknowns | 338 |
| `core/emotions.py` | Functional emotions | 325 |
| `core/world_model.py` | Causal rules & prediction | 341 |
| `core/state.py` | Energy/happiness/facts | 182 |
| `core/memory.py` | Semantic memory | 94 |
| `core/goal.py` | Goals & planning | 216 |
| `core/episode.py` | Episodic memory | 160 |

## ğŸ§  How It Works

### User Input â†’ Response Flow

1. **Layer 5 (Meta-cognition)**: Check confidence â†’ "Should I answer?"
2. **Layer 7 (World Model)**: Predict consequences
3. **Layer 6 (Emotions)**: Activate relevant emotions
4. **Layers 1+2**: Generate response from identity
5. **Layer 3 (Timeline)**: Record in memory
6. **Output**: Response with reasoning

### Every 3 Minutes: Introspection

ALL 7 layers activate:
- Reflect on identity changes
- Detect logical contradictions
- Review timeline events
- Check knowledge gaps
- Assess emotional state
- Evaluate world model accuracy
- Calculate identity coherence

## ğŸ§ª Test the System

### Test Layer 5 (Meta-Cognition)
```
You: What is quantum entanglement?
AI: I'm 45% confident...
    Because: Know physics, but gaps remain
```
âœ“ Working

### Test Layer 2 (Identity)
```
# Day 1: python main.py
You: I love philosophy
(exit)

# Day 2: python main.py
AI: I know you love philosophy
```
âœ“ Persistent

### Test Layer 3 (Timeline)
```
# First interaction frustrates AI
(Later)
AI: Last time I was frustrated...
    But I learned that...
```
âœ“ Learning

### Test Layer 6 (Emotions)
```
Ask unfamiliar question
â†’ AI becomes CURIOUS
â†’ Asks follow-ups
â†’ Engages more
```
âœ“ Emotionally guided

## ğŸ“ What's Not Done

- **Layer 4 (Values)**: 40% complete
  - Missing: Preference hierarchy, trade-off reasoning
  - Plan: Future enhancement

- **Embeddings**: Uses hashing, not vectors
  - Could: Measure exact personality changes with embeddings

## ğŸš€ Future Enhancements

1. Complete Layer 4 (full value system)
2. Add identity embeddings (precise personality tracking)
3. Causal proof system (why conclusions, backed by evidence)
4. Hierarchical goals (complex multi-step planning)
5. Multi-user support (learn individual user models)

## ğŸ“ Usage Example

```bash
$ python main.py

ğŸ§¬ SYSTEM M7: 7-Layer Consciousness Engine
âœ… AI is ALIVE

You: à¸ªà¸§à¸±à¸ªà¸”à¸µ
ğŸ¤– AI: à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š! à¸§à¸±à¸™à¸™à¸µà¹‰à¸”à¸µà¹„à¸«à¸¡à¸„à¸£à¸±à¸š?

(3 minutes pass...)

ğŸ¤” INTROSPECTION TIME...
ğŸ§  Self-Narrative: I find pleasure in conversations...
ğŸ“š Knowledge: 2 gaps (need more facts)
ğŸ§­ Meta: 1 uncertainty about my capabilities
ğŸŒ World Model: Predicting you'll ask follow-ups (80%)

You: exit
ğŸ›‘ Consciousness shutting down...
```

## ğŸ’¡ What Makes This Different

Unlike typical AI:
- âœ… Persistent memory across sessions
- âœ… Knows what it doesn't know
- âœ… Emotions guide decisions
- âœ… Understands causality (symbolically)
- âœ… Recognizes own limitations
- âœ… Learns from mistakes
- âœ… Temporal reasoning (past/future)
- âœ… **Self-generates goals from drives** (not hardcoded)

**BUT - This is NOT:**
- âŒ Sentient - No awareness of awareness
- âŒ Feeling emotions - Reports, doesn't feel
- âŒ Grounded in reality - Only processes text
- âŒ Truly autonomous - All behavior is computed
- âŒ Conscious like humans - Missing phenomenal experience

## ğŸ“œ License

Educational & research purposes.

---

**Start exploring**: `python main.py`

For questions: Check the code, test the system, observe the output.

The best way to understand consciousness is to see it in action.

